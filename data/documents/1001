中文自然语言处理技术
         从20世纪50年代初机器翻译课题被提出算起，自然语言处理（NLP）的研发历史至少也有50年了。90年代初,NLP的研究目标开始从小规模受限语言处理走向大规模真实文本处理。这个新目标在1990年在赫尔辛基举行的“第13届国际计算语言学大会”上被正式列入大会主题，大规模真是文本处理技术得到了较快发展，出现了一些可应用或者商用的成果。中文自然语言处理技术有以下几种：
         中文的自然语言处理 （Chinese Natural Language Processing）过程较英文复杂，其基础技术包括词语切词、词性标注、句法分析、语义角色标注和篇章处理等。
         1、词语切词：词的正确切分是进行中文文本处理的必要条件，中文分词的主要研究内容是歧义切分和未登录词识别。歧义切分是指对同一个文字片断具有不同的切分方式，如“结合成分子时”这句话就有好几种切分方法：“结合/成分/子时”、“结/合成/分子/时”、“结合/成/分子/时”等。但是正确的只有一种，能正确的进行歧义切分是分词的一个难点。分词的另一个难点是未登录词识别。所谓未登录词是指的是在词表中没有收录的词，主要包括时间词、数词、人名、地名、机构名等。
         从二十世纪八十年代初，中文分词（也称中文自动分词）技术得到了重视，经过这些年的发展，中文词语切分已经比较成熟，而中科院计算所开发了第一个开源的基于层叠隐马尔科夫模型的汉语词法分析系统ICTCLAS，该系统在第一届Sighan国际中文切词比赛中获得多项第一，开放源代码以后，被普遍采用。目前，基于统计的汉语切词系统准确率可以达到97%以上。
         2、词性标注：词性标注（Part-of-Speech tagging 或 POS
         tagging）是指对于句子中的每个词都指派一个合适的词性，也就是要确定每个词是名词、动词、形容词或其他词性的过程，又称词类标注或者简称标注。词性标注是自然语言处理中的一项基础任务，在语音识别、信息检索及自然语言处理的许多领域都发挥着重要的作用。目前，由于中文缺乏形态变化，仅仅依靠文本的局部上下文信息，很难准确地标注出词语的词性；定义本身在语言学家还存在争议，人工标注的一致性也比英语更低等原因，中文的词性标注准确率仍然较低（92%左右），低于英文的词性标注的准确率（97%以上）。
         3、句法分析：早期的研究工作集中于短语结构分析方面，这方面的工作以Collins和Charniak的工作最为著名，主要的方法都是词汇化的概率短语结构语法（Lexicalized PCFG）,短语结构分析目前主要采用的数据是宾州树库–在英文宾州树库上，句法分析的准确率可以达到92%--93%；而中文由于是由于中文缺乏明确的词性标记，可以用于帮助句法分析的信息太少，其句法分析的准确度也较低，如在中文宾州树库上，句法分析的准确率不到80%。
         4、语义角色标注：语义角色标注的目的是为句子中的每个动词标注出其相关的名词及其语义角色。语义角色标注通常都基于PropBank和FrameNet等语料库进行，中文的相关工作主要是基于PropBank。目前基于正确的句法树，英文和中文的语义角色标注准确率都可以达到91%左右；但基于自动的句法分析，英文的语义角色标注准确率大约在80%，而中文语义角色标注的准确率不到70%。
         5、篇章分析：篇章语义分析方面的典型应用是指代消解,
         包括单个文本和多个文本之中的指代消解。研究的内容包括人称代词与先行语的关系、命名实体的共指问题、指示代词消解所需的基本知识等。对于多个文本,内容包括命名实体的共指关系,如相同人名在不同文本中出现时,是否表示同一对象的问题等。我国有机构研究的研究项目表明，人名、地名、机构名三大命名实体共指消解具有较高的准确度,其中单数第三人称“他”的消解,在人民日报语料库上测试,超过了90%的准确度

